{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# DCAL Twin Faces Dataset - Data Exploration\n",
        "\n",
        "This notebook provides comprehensive analysis of the ND TWIN 2009-2010 dataset for twin face verification.\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append('../src')\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from collections import defaultdict, Counter\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Configure display\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "print(\"Setup complete!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Load Dataset Information\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset paths\n",
        "DATA_DIR = Path('../data')\n",
        "\n",
        "# Load dataset information\n",
        "with open(DATA_DIR / 'train_dataset_infor.json', 'r') as f:\n",
        "    train_info = json.load(f)\n",
        "\n",
        "with open(DATA_DIR / 'test_dataset_infor.json', 'r') as f:\n",
        "    test_info = json.load(f)\n",
        "\n",
        "with open(DATA_DIR / 'train_twin_pairs.json', 'r') as f:\n",
        "    train_pairs = json.load(f)\n",
        "\n",
        "with open(DATA_DIR / 'test_twin_pairs.json', 'r') as f:\n",
        "    test_pairs = json.load(f)\n",
        "\n",
        "print(f\"Train dataset: {len(train_info)} people\")\n",
        "print(f\"Test dataset: {len(test_info)} people\")\n",
        "print(f\"Train twin pairs: {len(train_pairs)} pairs\")\n",
        "print(f\"Test twin pairs: {len(test_pairs)} pairs\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Dataset Statistics and Analysis\n",
        "\n",
        "This section analyzes the basic statistics of the dataset including image counts, twin pairs, and quality metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_dataset_stats(dataset_info, dataset_name):\n",
        "    \"\"\"Analyze basic statistics of the dataset.\"\"\"\n",
        "    \n",
        "    # Count images per person\n",
        "    images_per_person = [len(images) for images in dataset_info.values()]\n",
        "    \n",
        "    # Total statistics\n",
        "    total_people = len(dataset_info)\n",
        "    total_images = sum(images_per_person)\n",
        "    \n",
        "    stats = {\n",
        "        'total_people': total_people,\n",
        "        'total_images': total_images,\n",
        "        'min_images_per_person': min(images_per_person),\n",
        "        'max_images_per_person': max(images_per_person),\n",
        "        'avg_images_per_person': np.mean(images_per_person),\n",
        "        'median_images_per_person': np.median(images_per_person),\n",
        "        'std_images_per_person': np.std(images_per_person)\n",
        "    }\n",
        "    \n",
        "    print(f\"\\n{dataset_name} Dataset Statistics:\")\n",
        "    print(f\"  Total people: {stats['total_people']}\")\n",
        "    print(f\"  Total images: {stats['total_images']}\")\n",
        "    print(f\"  Images per person: {stats['min_images_per_person']} - {stats['max_images_per_person']}\")\n",
        "    print(f\"  Average images per person: {stats['avg_images_per_person']:.2f}\")\n",
        "    print(f\"  Median images per person: {stats['median_images_per_person']:.2f}\")\n",
        "    print(f\"  Std images per person: {stats['std_images_per_person']:.2f}\")\n",
        "    \n",
        "    return stats, images_per_person\n",
        "\n",
        "# Analyze both datasets\n",
        "train_stats, train_images_per_person = analyze_dataset_stats(train_info, \"Train\")\n",
        "test_stats, test_images_per_person = analyze_dataset_stats(test_info, \"Test\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive visualization of dataset statistics\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Train dataset distribution\n",
        "axes[0, 0].hist(train_images_per_person, bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "axes[0, 0].set_title('Train Dataset: Images per Person Distribution')\n",
        "axes[0, 0].set_xlabel('Number of Images')\n",
        "axes[0, 0].set_ylabel('Number of People')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Test dataset distribution\n",
        "axes[0, 1].hist(test_images_per_person, bins=20, alpha=0.7, color='lightcoral', edgecolor='black')\n",
        "axes[0, 1].set_title('Test Dataset: Images per Person Distribution')\n",
        "axes[0, 1].set_xlabel('Number of Images')\n",
        "axes[0, 1].set_ylabel('Number of People')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Combined box plot\n",
        "data_to_plot = [train_images_per_person, test_images_per_person]\n",
        "axes[1, 0].boxplot(data_to_plot, labels=['Train', 'Test'])\n",
        "axes[1, 0].set_title('Images per Person: Train vs Test')\n",
        "axes[1, 0].set_ylabel('Number of Images')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Summary statistics table\n",
        "summary_data = {\n",
        "    'Dataset': ['Train', 'Test'],\n",
        "    'People': [train_stats['total_people'], test_stats['total_people']],\n",
        "    'Images': [train_stats['total_images'], test_stats['total_images']],\n",
        "    'Min Images/Person': [train_stats['min_images_per_person'], test_stats['min_images_per_person']],\n",
        "    'Max Images/Person': [train_stats['max_images_per_person'], test_stats['max_images_per_person']],\n",
        "    'Avg Images/Person': [f\"{train_stats['avg_images_per_person']:.2f}\", f\"{test_stats['avg_images_per_person']:.2f}\"]\n",
        "}\n",
        "\n",
        "# Create summary table\n",
        "axes[1, 1].axis('tight')\n",
        "axes[1, 1].axis('off')\n",
        "table = axes[1, 1].table(cellText=[[summary_data[col][i] for col in summary_data.keys()] for i in range(2)],\n",
        "                        colLabels=list(summary_data.keys()),\n",
        "                        cellLoc='center',\n",
        "                        loc='center')\n",
        "table.auto_set_font_size(False)\n",
        "table.set_fontsize(10)\n",
        "table.scale(1.2, 1.5)\n",
        "axes[1, 1].set_title('Dataset Summary Statistics')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Summary and Recommendations\n",
        "\n",
        "Based on the dataset analysis, here are the key findings and recommendations for training the DCAL Twin Faces Verification model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"DATASET ANALYSIS SUMMARY AND RECOMMENDATIONS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\n1. DATASET STATISTICS:\")\n",
        "print(f\"   - Train: {train_stats['total_people']} people, {train_stats['total_images']} images\")\n",
        "print(f\"   - Test: {test_stats['total_people']} people, {test_stats['total_images']} images\")\n",
        "print(f\"   - Train twin pairs: {len(train_pairs)}\")\n",
        "print(f\"   - Test twin pairs: {len(test_pairs)}\")\n",
        "\n",
        "print(\"\\n2. KEY OBSERVATIONS:\")\n",
        "print(f\"   - Images per person range: {train_stats['min_images_per_person']}-{train_stats['max_images_per_person']} (train), {test_stats['min_images_per_person']}-{test_stats['max_images_per_person']} (test)\")\n",
        "print(f\"   - Average images per person: {train_stats['avg_images_per_person']:.1f} (train), {test_stats['avg_images_per_person']:.1f} (test)\")\n",
        "print(f\"   - Standard deviation: {train_stats['std_images_per_person']:.1f} (train), {test_stats['std_images_per_person']:.1f} (test)\")\n",
        "\n",
        "print(\"\\n3. RECOMMENDATIONS:\")\n",
        "print(\"   - Image size: Use 224x224 for initial training, 448x448 for final models\")\n",
        "print(\"   - Batch size: 16 for local training, 8 for Kaggle\")\n",
        "print(\"   - Data augmentation: Face-preserving augmentations (rotation, flip, color jitter)\")\n",
        "print(\"   - Sampling strategy: Balanced positive/negative pairs with hard negative mining\")\n",
        "print(\"   - Validation split: 20% of training data for validation\")\n",
        "\n",
        "print(\"\\n4. TRAINING STRATEGY:\")\n",
        "print(\"   - Start with lower resolution (224x224) for faster experimentation\")\n",
        "print(\"   - Use multiple similarity functions (cosine, euclidean, learned)\")\n",
        "print(\"   - Implement attention visualization for interpretability\")\n",
        "print(\"   - Monitor both same-twin and different-twin accuracies\")\n",
        "print(\"   - Use transfer learning from pre-trained Vision Transformers\")\n",
        "\n",
        "print(\"\\n5. POTENTIAL CHALLENGES:\")\n",
        "print(\"   - High similarity between twins requires fine-grained discrimination\")\n",
        "print(\"   - Variable image quality and lighting conditions\")\n",
        "print(\"   - Limited training data compared to standard face recognition datasets\")\n",
        "print(\"   - Need for robust evaluation metrics (EER, ROC-AUC)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Dataset exploration complete! Ready for model training.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
